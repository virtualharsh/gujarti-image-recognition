{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing required libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np # for matrix calculations\nimport os # for file hiearchy handling\nimport matplotlib.pyplot as plt # plotting the images and data\nimport matplotlib.image as mpimg # reading the images\nfrom  sklearn.model_selection import train_test_split # for preprocessing \nfrom PIL import Image # image processing\nimport glob # file handing and folder scanner\nimport cv2 # for converting images to matrix","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:29:07.984768Z","iopub.execute_input":"2023-03-31T05:29:07.985172Z","iopub.status.idle":"2023-03-31T05:29:08.721072Z","shell.execute_reply.started":"2023-03-31T05:29:07.985136Z","shell.execute_reply":"2023-03-31T05:29:08.719858Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Getting folder paths of each images in list","metadata":{}},{"cell_type":"code","source":"listOfSubNumberDict = os.listdir(\"/kaggle/input/practice2/imgs\")\npath = '/kaggle/input/practice2/imgs/'\nlistOfSubNumberDict.sort()\nprint(listOfSubNumberDict)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:29:11.342293Z","iopub.execute_input":"2023-03-31T05:29:11.342840Z","iopub.status.idle":"2023-03-31T05:29:11.363245Z","shell.execute_reply.started":"2023-03-31T05:29:11.342786Z","shell.execute_reply":"2023-03-31T05:29:11.361867Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# getting data from images and display images","metadata":{}},{"cell_type":"code","source":"# getting views of images in dataset\nfilepath = \"/kaggle/input/practice2/imgs/0/1.jpg\"\nimg = Image.open(filepath)\n  \n# get width and height\nwidth = img.width\nheight = img.height\n  \n# display width and height\nprint(\"The height of the image is: \", height)\nprint(\"The width of the image is: \", width)\n\nImage.open(\"/kaggle/input/practice2/imgs/0/1.jpg\")","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:29:51.184762Z","iopub.execute_input":"2023-03-31T05:29:51.185185Z","iopub.status.idle":"2023-03-31T05:29:51.198704Z","shell.execute_reply.started":"2023-03-31T05:29:51.185148Z","shell.execute_reply":"2023-03-31T05:29:51.197446Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"The height of the image is:  70\nThe width of the image is:  50\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<PIL.JpegImagePlugin.JpegImageFile image mode=L size=50x70>","image/png":"iVBORw0KGgoAAAANSUhEUgAAADIAAABGCAAAAACr55i6AAACq0lEQVR4nO2Wy27bVhRFN0VSD8eWrbRFECAo+v9f01lHTRu3hWyZkig+74t3ddDEViS6QAadFDrDCy7ufc/Zh2CCvrUm30xckAvyv0Nco7ITQV2jUlK06r36cyT5smLNLF+/l5k6c1cmt6afz141wOcKfCQ4YLNl10NPEYfAwFk9q8h1d62/q64ymyiVjZ63GlIzf12lAho8FcPAIcuv5u8k4rkIzwhlVzmLpFSaaka/TbXk8V+MPV6/GdJkoWyXz8nS9STJ0lU5NcnrxiBWkjBo5iYasDg01bnKUSeTpVxkyCly2ydhqhBw2bSTSqfDmEoTJtdtfMr1hNvTBWexDyiBghj8yPUbtKBxXP3Ozg/sLKz5w+0nGiJFOdaxuE4E9MI3WGNd1WHwvBfbLb4bQTwieNdvuQ/eE0qKNZH1RGngrxhGkCGqGAxQw751UFG2VYm/Fu6rib5c//AdNVT7vr+3uLqgx0BRI9E2ZgRxCB6xBE9XEzkQa9sS+lz/5PUM6cKbQ2g255PbSuDHEPYiRLpTouWdVH86OnmZfpqZaHZne5Xpl9k8/dG+nDw/4vL3q7h4uz9FCq1ys7gfj6UEn059QUCLuB8zVmmayX84nKr4dlja5LoZMbb8dRmecm5PkTRPTeyzcJT4Lyu2XynBkUxPEJIhn4RIeq6yKs1NMs0yI6uogzo1TgcNifJkkNLjt3yuDTHVlt5V4D2R39hB5Vs3E1Tt2ChdhVYOsNBiaguWEFCK+Xjcwpfwrwn7XOGBPx0WHLXf1w9oJr6O8kv4KQZzo1s2tIFqP2xqBx/0AyYSYjOCtPBAlHQDrbEMcCdpvgFTU4+pHKhaHPyka6XLVPpeugvYZig6fmbscwEDNbg4LBJpcZMJamOgxz/B0SInl/+xC3JBLsh/hvwNe4gIPOC1AvUAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# finding number of images in each folder","metadata":{}},{"cell_type":"code","source":"for i in listOfSubNumberDict:\n      print(f'there is {len(os.listdir(f\"/kaggle/input/practice2/imgs/{i}\"))} of images of {i}')","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:32:08.771813Z","iopub.execute_input":"2023-03-31T05:32:08.773001Z","iopub.status.idle":"2023-03-31T05:32:08.790670Z","shell.execute_reply.started":"2023-03-31T05:32:08.772953Z","shell.execute_reply":"2023-03-31T05:32:08.789045Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"there is 130 of images of 0\nthere is 130 of images of 1\nthere is 130 of images of 2\nthere is 130 of images of 3\nthere is 130 of images of 4\nthere is 130 of images of 5\nthere is 130 of images of 6\nthere is 130 of images of 7\nthere is 130 of images of 8\nthere is 130 of images of 9\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# converting all images of 0-9 to matrix in form of numpy array","metadata":{}},{"cell_type":"code","source":"img_extension = ['jpg']\nfiles = []\n\nfor i in listOfSubNumberDict:\n    allImgPath = f'/kaggle/input/practice2/imgs/{i}/'\n    [files.extend(glob.glob(allImgPath + '*.' + e)) for e in img_extension]\n\nallImg = np.asarray([cv2.imread(file) for file in files])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:32:52.501086Z","iopub.execute_input":"2023-03-31T05:32:52.501530Z","iopub.status.idle":"2023-03-31T05:32:55.777434Z","shell.execute_reply.started":"2023-03-31T05:32:52.501488Z","shell.execute_reply":"2023-03-31T05:32:55.776170Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# getting information of matrix converted from images","metadata":{}},{"cell_type":"code","source":"print(allImg.shape)\nprint(allImg[0].shape)\nprint(allImg.dtype)\nprint(type(allImg))\nprint(len(allImg))","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:33:29.516898Z","iopub.execute_input":"2023-03-31T05:33:29.517304Z","iopub.status.idle":"2023-03-31T05:33:29.524365Z","shell.execute_reply.started":"2023-03-31T05:33:29.517271Z","shell.execute_reply":"2023-03-31T05:33:29.523086Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(1300, 70, 50, 3)\n(70, 50, 3)\nuint8\n<class 'numpy.ndarray'>\n1300\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# labelling the list of images for training","metadata":{}},{"cell_type":"code","source":"counter = 0\ndig = 0\nlabels = []\nfor i in range(0,130):\n    labels.append(0)\n\nwhile(dig<=9):\n    if(counter%130==0):\n        dig +=1\n    labels.append(dig)\n    counter+=1\nlabels.remove(10)\nlabels = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:36:24.950913Z","iopub.execute_input":"2023-03-31T05:36:24.951360Z","iopub.status.idle":"2023-03-31T05:36:24.959068Z","shell.execute_reply.started":"2023-03-31T05:36:24.951325Z","shell.execute_reply":"2023-03-31T05:36:24.957784Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# verifing the labels","metadata":{}},{"cell_type":"code","source":"print(labels)\nc=0\nfor i in range(0,10):\n    for j in labels:\n        if i==j:\n            c += 1\n    print(f\"number of {i} is {c}\")\n    c = 0","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:40:59.351968Z","iopub.execute_input":"2023-03-31T05:40:59.353031Z","iopub.status.idle":"2023-03-31T05:40:59.366174Z","shell.execute_reply.started":"2023-03-31T05:40:59.352982Z","shell.execute_reply":"2023-03-31T05:40:59.364789Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"[0 0 0 ... 9 9 9]\nnumber of 0 is 130\nnumber of 1 is 130\nnumber of 2 is 130\nnumber of 3 is 130\nnumber of 4 is 130\nnumber of 5 is 130\nnumber of 6 is 130\nnumber of 7 is 130\nnumber of 8 is 130\nnumber of 9 is 130\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# scaling the matrix for getting values of each elements 0-1 that will optimise the training","metadata":{}},{"cell_type":"code","source":"for i in range(0, len(allImg)):\n    allImg[i] = allImg[i]/255\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:41:02.489166Z","iopub.execute_input":"2023-03-31T05:41:02.489552Z","iopub.status.idle":"2023-03-31T05:41:02.525663Z","shell.execute_reply.started":"2023-03-31T05:41:02.489518Z","shell.execute_reply":"2023-03-31T05:41:02.524309Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Train - Test Split for finding accuracy of unidentified images","metadata":{}},{"cell_type":"code","source":"X = allImg\nY = np.asarray(labels)\nx_train , x_test , y_train , y_test = train_test_split(X,Y,test_size=0.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:41:32.792110Z","iopub.execute_input":"2023-03-31T05:41:32.792507Z","iopub.status.idle":"2023-03-31T05:41:32.810832Z","shell.execute_reply.started":"2023-03-31T05:41:32.792474Z","shell.execute_reply":"2023-03-31T05:41:32.809188Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# getting number of images splitted by train test split","metadata":{}},{"cell_type":"code","source":"print (f'The X images are splitted into train set : {len(x_train)} test set : {len(x_test)}')\nprint (f'The Y labels are splitted into train set : {len(y_train)} test set : {len(y_test)}')\nprint(x_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:41:33.958226Z","iopub.execute_input":"2023-03-31T05:41:33.958996Z","iopub.status.idle":"2023-03-31T05:41:33.967522Z","shell.execute_reply.started":"2023-03-31T05:41:33.958948Z","shell.execute_reply":"2023-03-31T05:41:33.966207Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"The X images are splitted into train set : 1040 test set : 260\nThe Y labels are splitted into train set : 1040 test set : 260\n[[[1 1 1]\n  [1 1 1]\n  [1 1 1]\n  ...\n  [1 1 1]\n  [1 1 1]\n  [1 1 1]]\n\n [[1 1 1]\n  [1 1 1]\n  [1 1 1]\n  ...\n  [1 1 1]\n  [1 1 1]\n  [1 1 1]]\n\n [[1 1 1]\n  [1 1 1]\n  [1 1 1]\n  ...\n  [1 1 1]\n  [1 1 1]\n  [1 1 1]]\n\n ...\n\n [[1 1 1]\n  [1 1 1]\n  [1 1 1]\n  ...\n  [1 1 1]\n  [1 1 1]\n  [1 1 1]]\n\n [[1 1 1]\n  [1 1 1]\n  [1 1 1]\n  ...\n  [1 1 1]\n  [1 1 1]\n  [1 1 1]]\n\n [[1 1 1]\n  [1 1 1]\n  [1 1 1]\n  ...\n  [1 1 1]\n  [1 1 1]\n  [1 1 1]]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# importing tensorflow for building the model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:41:39.274382Z","iopub.execute_input":"2023-03-31T05:41:39.274931Z","iopub.status.idle":"2023-03-31T05:41:48.777322Z","shell.execute_reply.started":"2023-03-31T05:41:39.274880Z","shell.execute_reply":"2023-03-31T05:41:48.775679Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# implementing neural network","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:41:49.945090Z","iopub.execute_input":"2023-03-31T05:41:49.945945Z","iopub.status.idle":"2023-03-31T05:41:50.111184Z","shell.execute_reply.started":"2023-03-31T05:41:49.945900Z","shell.execute_reply":"2023-03-31T05:41:50.110028Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# feed the model with our training matrix and testing labels","metadata":{}},{"cell_type":"code","source":"model.fit(x_train, y_train, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:46:09.072523Z","iopub.execute_input":"2023-03-31T05:46:09.072917Z","iopub.status.idle":"2023-03-31T05:46:13.563362Z","shell.execute_reply.started":"2023-03-31T05:46:09.072881Z","shell.execute_reply":"2023-03-31T05:46:13.562158Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/10\n33/33 [==============================] - 0s 14ms/step - loss: 0.1337 - accuracy: 0.9644\nEpoch 2/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.1336 - accuracy: 0.9712\nEpoch 3/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0909 - accuracy: 0.9846\nEpoch 4/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0858 - accuracy: 0.9856\nEpoch 5/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0597 - accuracy: 0.9962\nEpoch 6/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0424 - accuracy: 0.9971\nEpoch 7/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0364 - accuracy: 1.0000\nEpoch 8/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0285 - accuracy: 1.0000\nEpoch 9/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0273 - accuracy: 1.0000\nEpoch 10/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 1.0000\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fd40ee6d1d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# finding loss and accuracy of unidentified images","metadata":{}},{"cell_type":"code","source":"val_loss, val_acc = model.evaluate(x_test, y_test)\nprint(val_loss)\nprint(val_acc*100)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T05:46:13.565029Z","iopub.execute_input":"2023-03-31T05:46:13.565570Z","iopub.status.idle":"2023-03-31T05:46:13.672882Z","shell.execute_reply.started":"2023-03-31T05:46:13.565536Z","shell.execute_reply":"2023-03-31T05:46:13.671952Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"9/9 [==============================] - 0s 4ms/step - loss: 0.9341 - accuracy: 0.7538\n0.9341462254524231\n75.38461685180664\n","output_type":"stream"}]}]}